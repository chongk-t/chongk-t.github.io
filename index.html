
 <!DOCTYPE HTML>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
  
    <title>Coding Thoughts</title>
    <meta name="viewport" content="width=device-width, initial-scale=1,user-scalable=no">
    
    <meta name="author" content="Chongk-t">
    

    
    <meta name="description" content="Coding Thinking">
<meta property="og:type" content="website">
<meta property="og:title" content="Coding Thoughts">
<meta property="og:url" content="http://chongk-t.github.io/index.html">
<meta property="og:site_name" content="Coding Thoughts">
<meta property="og:description" content="Coding Thinking">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Coding Thoughts">
<meta name="twitter:description" content="Coding Thinking">

    
    <link rel="alternative" href="/atom.xml" title="Coding Thoughts" type="application/atom+xml">
    
    
    <link rel="icon" href="/img/favicon.ico">
    
    
    <link rel="apple-touch-icon" href="/img/jacman.jpg">
    <link rel="apple-touch-icon-precomposed" href="/img/jacman.jpg">
    
    <link rel="stylesheet" href="/css/style.css" type="text/css">
</head>

  <body>
    <header>
      
<div>
		
			<div id="imglogo">
				<a href="/"><img src="/img/logo.png" alt="Coding Thoughts" title="Coding Thoughts"/></a>
			</div>
			
			<div id="textlogo">
				<h1 class="site-name"><a href="/" title="Coding Thoughts">Coding Thoughts</a></h1>
				<h2 class="blog-motto">Thinking and coding down.</h2>
			</div>
			<div class="navbar"><a class="navbutton navmobile" href="#" title="菜单">
			</a></div>
			<nav class="animated">
				<ul>
					<ul>
					 
						<li><a href="/">Home</a></li>
					
						<li><a href="/archives">Archives</a></li>
					
						<li><a href="/about">About</a></li>
					
					<li>
 					
					<form class="search" action="//google.com/search" method="get" accept-charset="utf-8">
						<label>Search</label>
						<input type="search" id="search" name="q" autocomplete="off" maxlength="20" placeholder="搜索" />
						<input type="hidden" name="q" value="site:chongk-t.github.io">
					</form>
					
					</li>
				</ul>
			</nav>			
</div>
    </header>
    <div id="container">
      <div id="main">

   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2016/01/27/TeraSort-output-replication/" title="" itemprop="url"></a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Chongk-t" target="_blank" itemprop="author">Chongk-t</a>
		
  <p class="article-time">
    <time datetime="2016-01-27T02:40:16.726Z" itemprop="datePublished"> 发表于 2016-01-27</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h1 id="Terasort_output_replication">Terasort output replication</h1><hr>
<p>最近一直在关注TeraSort。<br>有时候你非常关注某些东西是却会忽略其他一些很基本的东西。比如TeraSort，我一直很关注如何Map更快、Shuffle更快、Reduce更快，回来却发现有个空白竟然没关注到，着实吓了一跳。</p>
<p>回归正题。某一天我一抬头，看到了TeraSort的网络性能图，<br><img src="http://ww4.sinaimg.cn/mw690/79382a93jw1f0dun08ep1j20mn07saab.jpg" alt="两头空白"><br>为什么会是两头空白？好吧，Hadoop为Map任务做了Locality Based处理，Map阶段没有网络流量我能理解。然而，Reduce阶段呢？至少TeraSort会将输出数据写入到HDFS的，说好的3备份直接的数据传递产生的网络流量呢？<br>是不是输出文件的3备份除了问题呢？<br>Hadoop提供了hadoop fsck /FILE-PATH  -files -locations -blocks查看文件块的保存地点及路径。通过查看，果然，TeraSort的输出文件块备份为1。</p>
<p>从代码中找找确认一下。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">job.getConfiguration().setInt(<span class="string">"dfs.replication"</span>, getOutputReplication(job));</span><br><span class="line">    TeraOutputFormat.setFinalSync(job, <span class="keyword">true</span>);</span><br></pre></td></tr></table></figure></p>
<p>从上面代码可以看到，TeraSort确实更新了dfs.replication设置，而<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">getOutputReplication</span><span class="params">(JobContext job)</span> </span>&#123;</span><br><span class="line">   <span class="keyword">return</span> job.getConfiguration().getInt(OUTPUT_REPLICATION, <span class="number">1</span>);</span><br><span class="line"> &#125;</span><br><span class="line"> ......</span><br><span class="line"> <span class="keyword">static</span> String OUTPUT_REPLICATION = <span class="string">"mapreduce.terasort.output.replication"</span>;</span><br></pre></td></tr></table></figure></p>
<p>如果mapreduce.terasort.output.replication设置成3从命令行传入，期待的网络流量出来了。<br><img src="http://ww3.sinaimg.cn/mw690/79382a93jw1f0dun0r5cjj20mm07smxk.jpg" alt="找回reduce流量"><br>应该是TeraSort觉得输出数据不重要不需要多备份吧。</p>
<p>有时候，太关注一些事情时，会让你忽略掉其他的很多信息。</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


</div>




<div class="comments-count">
	
	  	<span></span>
		<a href="/2016/01/27/TeraSort-output-replication/#disqus_thread" class="comments-count-link">Comments</a>
	
</div>

</footer>


    </article>






   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2016/01/26/chroot/" title="" itemprop="url"></a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Chongk-t" target="_blank" itemprop="author">Chongk-t</a>
		
  <p class="article-time">
    <time datetime="2016-01-26T08:56:44.316Z" itemprop="datePublished"> 发表于 2016-01-26</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h1 id="聊聊chroot">聊聊chroot</h1><hr>
<p>这里有一篇很棒的<a href="http://www.ibm.com/developerworks/cn/linux/l-cn-chroot/index.html" target="_blank" rel="external">文章</a>关于chroot如何使用。</p>
<p>其实在Linux的源码(2.6.32)中，最后一部分是使用到了Chroot的。我们知道，Linux内核在启动过程中，完成了内存、cpu等等最基础资源的的初始化之后将要挂载Initrd，然后执行Initrd中的一系列命令。当Initrd中的任务执行完之后，Linux将要挂载硬盘文件系统，作为启动后的工作文件系统。这个过程中就使用到了chroot。</p>
<p>当然chroot对应的root并不是文件系统中的/root目录。我的理解是change root inode。大家知道，对Linux来说，无论是磁盘中的文件、目录都对应着一个inode。那么，文件系统中的数据是如何访问的呢？在Linux中，系统使用一个root inode保存当前文件系统的入口，当然默认情况对应的是文件系统的根目录。当用户需要访问文件系统中的某一个文件时，例如对应的路径是/a/b/c/xx时，Linux对文件路径的解析是从root inode找到a目录对应的inode，再从a目录下对应的inodes中找到目录b对应的inode，层层寻找最终找到xx文件对应的inode。从上面这个过程我们可以看到，root inode作为整个文件访问的入口的作用。</p>
<p>当我们使用chroot将root inode替换之后，文件系统的入口变成了整个磁盘文件系统的某一个目录时，系统中的文件访问路径自然也有了相应的局限，局限到一个某个目录中，这也就达到了chroot的种种错误隔离之类的效果。</p>
<p>这里说说我之前的一个疑问。我们之前做了一个多OS系统，每个OS使用宿主OS的一个目录，为了兼容整个应用执行的环境，我们需要将目标OS的文件访问路径进行chroot。其实这个场景在Linux Container中也非常常见。那么问题来了，对于某个系统来说，我们能用符号链接将宿主系统的/bin、/lib、/sbin之类的目录链接到目标系统的工作目录下以共享使用么？<br>答案是不行的。因为符号链接对于Linux来说是一个特殊的文件，里边保存了目标文件的的路径。那么，既然你整个文件系统的路径都已经变了，符号链接中的目录自然也找不到了。<br>这个问题其实使用硬链接就可以解决。硬链接相当于将目标目录的inode挂在本目录下。那么，既然inode都是一样的，系统根据该inode可以找到bin中的文件，访问路径也就没问题了。</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


</div>




<div class="comments-count">
	
	  	<span></span>
		<a href="/2016/01/26/chroot/#disqus_thread" class="comments-count-link">Comments</a>
	
</div>

</footer>


    </article>






   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2016/01/22/NodeManagerResourceReport/" title="NodeManager资源注册" itemprop="url">NodeManager资源注册</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Chongk-t" target="_blank" itemprop="author">Chongk-t</a>
		
  <p class="article-time">
    <time datetime="2016-01-22T15:43:53.138Z" itemprop="datePublished"> 发表于 2016-01-22</time>
    
  </p>
</header>
    <div class="article-content">
        
        <p>最近非常好奇的一个问题是：在Yarn中，Container是如何进行轮转的？<br>因而在最近的一系列文章中，我们将探究Yarn的Container资源管理机制。本篇文章作为基础，分析一下NodeManager在启动时如何向ResourceManager注册资源。</p>
<h3 id="NodeManager向ResourceManager汇报资源">NodeManager向ResourceManager汇报资源</h3><p>我们首先跟踪NodeManager代码，在NodeManager类的ServiceInit函数中可以看到如下代码：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// StatusUpdater should be added last so that it get started last </span></span><br><span class="line"><span class="comment">// so that we make sure everything is up before registering with RM. </span></span><br><span class="line">addService(nodeStatusUpdater);</span><br></pre></td></tr></table></figure></p>
<p>好吧，从注释我们可以看到，nodeStatusUpdater是最后向RM注册的服务。既然找到了开端，那我们就接着往下跟踪。nodeStatusUpdater是一个NodeStatusUpdaterImpl类的对象，我们看看它的ServiceInit以及ServiceStart。在ServiceInit中，nodeStatusUpdater首先从配置文件获取了节点资源相关的配置：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> memoryMb = </span><br><span class="line">        conf.getInt(</span><br><span class="line">            YarnConfiguration.NM_PMEM_MB, YarnConfiguration.DEFAULT_NM_PMEM_MB);</span><br><span class="line"><span class="keyword">float</span> vMemToPMem =             </span><br><span class="line">    conf.getFloat(</span><br><span class="line">        YarnConfiguration.NM_VMEM_PMEM_RATIO, </span><br><span class="line">        YarnConfiguration.DEFAULT_NM_VMEM_PMEM_RATIO); </span><br><span class="line"><span class="keyword">int</span> virtualMemoryMb = (<span class="keyword">int</span>)Math.ceil(memoryMb * vMemToPMem);</span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> virtualCores =</span><br><span class="line">    conf.getInt(</span><br><span class="line">        YarnConfiguration.NM_VCORES, YarnConfiguration.DEFAULT_NM_VCORES);</span><br><span class="line"></span><br><span class="line"><span class="keyword">this</span>.totalResource = Resource.newInstance(memoryMb, virtualCores);</span><br></pre></td></tr></table></figure></p>
<p>在ServiceStart中，NodeManager通过与RM的代理向ResourceManager注册，代码如下所示：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">RegisterNodeManagerRequest request =</span><br><span class="line">    RegisterNodeManagerRequest.newInstance(nodeId, httpPort, totalResource,</span><br><span class="line">      nodeManagerVersionId, containerReports, getRunningApplications());</span><br><span class="line"><span class="keyword">if</span> (containerReports != <span class="keyword">null</span>) &#123;</span><br><span class="line">  LOG.info(<span class="string">"Registering with RM using containers :"</span> + containerReports);</span><br><span class="line">&#125;</span><br><span class="line">RegisterNodeManagerResponse regNMResponse =</span><br><span class="line">    resourceTracker.registerNodeManager(request);</span><br><span class="line"><span class="keyword">this</span>.rmIdentifier = regNMResponse.getRMIdentifier();</span><br></pre></td></tr></table></figure></p>
<p>在request的构造中，我们看到有一项是totalResource，可以知道此时NodeManager已经将自身包含的资源向ResourceManager进行注册。接着NodeStatusUpdaterImpl将启动一个心跳线程定时向RM发送心跳信息，并执行RM随心跳信息返回的操作：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">removeOrTrackCompletedContainersFromContext(response</span><br><span class="line">    .getContainersToBeRemovedFromNM());</span><br><span class="line"></span><br><span class="line">lastHeartBeatID = response.getResponseId();</span><br><span class="line">List&lt;ContainerId&gt; containersToCleanup = response</span><br><span class="line">    .getContainersToCleanup();</span><br><span class="line"><span class="keyword">if</span> (!containersToCleanup.isEmpty()) &#123;</span><br><span class="line">  dispatcher.getEventHandler().handle(</span><br><span class="line">      <span class="keyword">new</span> CMgrCompletedContainersEvent(containersToCleanup,</span><br><span class="line">        CMgrCompletedContainersEvent.Reason.BY_RESOURCEMANAGER));</span><br><span class="line">&#125;</span><br><span class="line">List&lt;ApplicationId&gt; appsToCleanup =</span><br><span class="line">    response.getApplicationsToCleanup();</span><br><span class="line"><span class="comment">//Only start tracking for keepAlive on FINISH_APP</span></span><br><span class="line">trackAppsForKeepAlive(appsToCleanup);</span><br><span class="line"><span class="keyword">if</span> (!appsToCleanup.isEmpty()) &#123;</span><br><span class="line">  dispatcher.getEventHandler().handle(</span><br><span class="line">      <span class="keyword">new</span> CMgrCompletedAppsEvent(appsToCleanup,</span><br><span class="line">          CMgrCompletedAppsEvent.Reason.BY_RESOURCEMANAGER));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>然而，在这里我们只看到了NodeManager向ResourceManager汇报Container状态并执行ResourceManager要求清理或移除Container的操作。那么，ResourceManager要求NodeManager创建Container的操作逻辑在哪儿呢？</p>
<h3 id="ResourceManager对NodeManager注册事件的处理">ResourceManager对NodeManager注册事件的处理</h3><p>在RM的初始化服务过程中注册了NodeEventDispatcher服务，该服务将处理NM的注册事件。RMNodeImpl是Node注册事件的Handler，它使用了一个状态机来处理来自于NM的事件。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//Transitions from NEW state</span></span><br><span class="line">.addTransition(NodeState.NEW, NodeState.RUNNING, </span><br><span class="line">    RMNodeEventType.STARTED, <span class="keyword">new</span> AddNodeTransition())</span><br><span class="line">.addTransition(NodeState.NEW, NodeState.NEW,</span><br><span class="line">    RMNodeEventType.RESOURCE_UPDATE, </span><br><span class="line">    <span class="keyword">new</span> UpdateNodeResourceWhenUnusableTransition())</span><br></pre></td></tr></table></figure></p>
<p>Node注册最先由AddNodeTransition处理。这个函数通过<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">rmNode.context.getDispatcher().getEventHandler()</span><br><span class="line">  .handle(<span class="keyword">new</span> NodeAddedSchedulerEvent(rmNode, containers));</span><br><span class="line">rmNode.context.getDispatcher().getEventHandler().handle(</span><br><span class="line">  <span class="keyword">new</span> NodesListManagerEvent(</span><br><span class="line">      NodesListManagerEventType.NODE_USABLE, rmNode));</span><br></pre></td></tr></table></figure></p>
<p>将NM注册事件交由CapacityScheduler处理（对应NODE_ADDED事件），并用NODE_USABLE事件将该NM更新到NodeListManager中。在NODE_ADDED事件中，CapacityScheduler将该Node对应的资源更新到clusterResource中：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Resources.addTo(clusterResource, nodeManager.getTotalCapability());</span><br><span class="line"></span><br><span class="line"><span class="comment">// update this node to node label manager</span></span><br><span class="line"><span class="keyword">if</span> (labelManager != <span class="keyword">null</span>) &#123;</span><br><span class="line">  labelManager.activateNode(nodeManager.getNodeID(),</span><br><span class="line">      nodeManager.getTotalCapability());</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">root.updateClusterResource(clusterResource, <span class="keyword">new</span> ResourceLimits(</span><br><span class="line">    clusterResource));</span><br></pre></td></tr></table></figure></p>
<p>NodeListManager处理NODE_USABLE事件将该Node加入到updatedNodes中。<br>OK，资源已经收集好了，接下来就是资源分配了。</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


</div>




<div class="comments-count">
	
	  	<span></span>
		<a href="/2016/01/22/NodeManagerResourceReport/#disqus_thread" class="comments-count-link">Comments</a>
	
</div>

</footer>


    </article>






   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2016/01/20/teragen/" title="揭底teragen" itemprop="url">揭底teragen</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Chongk-t" target="_blank" itemprop="author">Chongk-t</a>
		
  <p class="article-time">
    <time datetime="2016-01-20T13:06:55.541Z" itemprop="datePublished"> 发表于 2016-01-20</time>
    
  </p>
</header>
    <div class="article-content">
        
        <p>昨天跟同事们谈起TeraSort的一些问题，忽然想到TeraGen。之前对TeraGen有一个大概的概念-TeraSort的数据生成器，生成100byte的Record。既然好奇，这次就索性分析一下TeraGen的源码。</p>
<p>首先来看看TeraGen的启动代码：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">setNumberOfRows(job, parseHumanLong(args[<span class="number">0</span>]));</span><br><span class="line">Path outputDir = <span class="keyword">new</span> Path(args[<span class="number">1</span>]);</span><br><span class="line">FileOutputFormat.setOutputPath(job, outputDir);</span><br><span class="line">job.setJobName(<span class="string">"TeraGen"</span>);</span><br><span class="line">job.setJarByClass(TeraGen.class);</span><br><span class="line">job.setMapperClass(SortGenMapper.class);</span><br><span class="line">job.setNumReduceTasks(<span class="number">0</span>);</span><br><span class="line">job.setOutputKeyClass(Text.class);</span><br><span class="line">job.setOutputValueClass(Text.class);</span><br><span class="line">job.setInputFormatClass(RangeInputFormat.class);</span><br><span class="line">job.setOutputFormatClass(TeraOutputFormat.class);</span><br><span class="line"><span class="keyword">return</span> job.waitForCompletion(<span class="keyword">true</span>) ? <span class="number">0</span> : <span class="number">1</span>;</span><br></pre></td></tr></table></figure></p>
<p>TeraGen的输入一共有两个，num rows以及 output dir。从上面初始化代码部分可以看到，TeraGen使用的map类是SortGenMapper，不需要Reduce阶段，InputFormat类是RangeInputFormat，OutputFormat类是TeraOutputFormat。</p>
<p>首先，我们分析Map阶段的输入。根据MapReduce程序的执行流程，在Map阶段之前系统将首先分析输入文件，计算Split等，因而我们先看RangeInputFormat类：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> List&lt;InputSplit&gt; <span class="title">getSplits</span><span class="params">(JobContext job)</span> </span>&#123;</span><br><span class="line">      <span class="keyword">long</span> totalRows = getNumberOfRows(job);</span><br><span class="line">      <span class="keyword">int</span> numSplits = job.getConfiguration().getInt(MRJobConfig.NUM_MAPS, <span class="number">1</span>);</span><br><span class="line">      LOG.info(<span class="string">"Generating "</span> + totalRows + <span class="string">" using "</span> + numSplits);</span><br><span class="line">      List&lt;InputSplit&gt; splits = <span class="keyword">new</span> ArrayList&lt;InputSplit&gt;();</span><br><span class="line">      <span class="keyword">long</span> currentRow = <span class="number">0</span>;</span><br><span class="line">      <span class="keyword">for</span>(<span class="keyword">int</span> split = <span class="number">0</span>; split &lt; numSplits; ++split) &#123;</span><br><span class="line">        <span class="keyword">long</span> goal = </span><br><span class="line">          (<span class="keyword">long</span>) Math.ceil(totalRows * (<span class="keyword">double</span>)(split + <span class="number">1</span>) / numSplits);</span><br><span class="line">        splits.add(<span class="keyword">new</span> RangeInputSplit(currentRow, goal - currentRow));</span><br><span class="line">        currentRow = goal;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">return</span> splits;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></p>
<p>先看getSplits方法，该方法由Hadoop框架调用，获得split的描述数组，每个split将对应一个map任务。从上面的代码可以看出，numSplits由NUM_MAPS输入项确定，初次之外生成数据总行数也由配置输入。对于每一个Split，函数中计算Split的初始值以及行数。也就是说，每个Map需要产生数据的开始行以及行数都由Split中保存好了。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(LongWritable row, NullWritable ignored,</span><br><span class="line">        Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">      <span class="keyword">if</span> (rand == <span class="keyword">null</span>) &#123;</span><br><span class="line">        rowId = <span class="keyword">new</span> Unsigned16(row.get());</span><br><span class="line">        rand = Random16.skipAhead(rowId);</span><br><span class="line">        checksumCounter = context.getCounter(Counters.CHECKSUM);</span><br><span class="line">      &#125;</span><br><span class="line">      Random16.nextRand(rand);</span><br><span class="line">      GenSort.generateRecord(buffer, rand, rowId);</span><br><span class="line">      key.set(buffer, <span class="number">0</span>, TeraInputFormat.KEY_LENGTH);</span><br><span class="line">      value.set(buffer, TeraInputFormat.KEY_LENGTH, </span><br><span class="line">                TeraInputFormat.VALUE_LENGTH);</span><br><span class="line">      context.write(key, value);</span><br><span class="line">      crc32.reset();</span><br><span class="line">      crc32.update(buffer, <span class="number">0</span>, </span><br><span class="line">                   TeraInputFormat.KEY_LENGTH + TeraInputFormat.VALUE_LENGTH);</span><br><span class="line">      checksum.set(crc32.getValue());</span><br><span class="line">      total.add(checksum);</span><br><span class="line">      rowId.add(ONE);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>我们再看看map函数。按照Hadoop的执行流程，框架通过haveNextValue和getCurrentKey从RecordReader中获取输入，并传递给map函数。从TeraGen源码中的RangeRecordReader我们可以知道，getCurrentKey返回的就是当前的Row号。从Map函数可知，map使用rowid生成一个100字节的数据保存在Buffer中，并以10字节为key、90字节为value的形式写入到Context中。<br>在Hadoop中，当Reduce数设置为0时，map的输出将通过配置输出方式输出，在TeraGen中将使用TeraOutputFormat输出。我们看看这个输出类中的实现。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">TeraRecordWriter</span> <span class="keyword">extends</span> <span class="title">RecordWriter</span>&lt;<span class="title">Text</span>,<span class="title">Text</span>&gt; </span>&#123;</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">boolean</span> finalSync = <span class="keyword">false</span>;</span><br><span class="line">  <span class="keyword">private</span> FSDataOutputStream out;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="title">TeraRecordWriter</span><span class="params">(FSDataOutputStream out,</span><br><span class="line">                          JobContext job)</span> </span>&#123;</span><br><span class="line">    finalSync = getFinalSync(job);</span><br><span class="line">    <span class="keyword">this</span>.out = out;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">write</span><span class="params">(Text key, </span><br><span class="line">                                 Text value)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    out.write(key.getBytes(), <span class="number">0</span>, key.getLength());</span><br><span class="line">    out.write(value.getBytes(), <span class="number">0</span>, value.getLength());</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">(TaskAttemptContext context)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (finalSync) &#123;</span><br><span class="line">      out.sync();</span><br><span class="line">    &#125;</span><br><span class="line">    out.close();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>我们可以看到，最终Map结束以后数据以先Key后Value的形式写入到HDFS。</p>
<p>按照Hadoop的框架，map函数将key/value对输出到Sort缓冲区中，当缓冲区满时spill线程按照key对数据进行排序，并输出到磁盘。至此，TeraGen的整个数据生成过程理清了。</p>
<p>现在还有一个问题，在计算TeraGen的进度时，是否会包括HDFS的操作时间？当任务进度为100%，是最后一个key/value对刚刚写入Context还是所有的数据都已经写入到HDFS？这个问题我们将在之后继续探究。</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


</div>




<div class="comments-count">
	
	  	<span></span>
		<a href="/2016/01/20/teragen/#disqus_thread" class="comments-count-link">Comments</a>
	
</div>

</footer>


    </article>






   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2016/01/11/hadoop-rack/" title="hadoop网络拓扑" itemprop="url">hadoop网络拓扑</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Chongk-t" target="_blank" itemprop="author">Chongk-t</a>
		
  <p class="article-time">
    <time datetime="2016-01-11T03:02:32.246Z" itemprop="datePublished"> 发表于 2016-01-11</time>
    
  </p>
</header>
    <div class="article-content">
        
        <p>最近忙的一件事是收到来自同事的需求，探索Hadoop的网络支撑环境。于是我决定先看看Hadoop对于网络拓扑的支持情况。</p>
<h3 id="Hadoop_Rack_Awareness">Hadoop Rack Awareness</h3><p>在Apache的Hadoop文档中有一段对<a href="https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-common/RackAwareness.html" target="_blank" rel="external">Rack Awareness</a>的介绍。Hadoop会根据Rack的情况进行容错部署，例如至少将一个备份块放置在不同的Rack中。根据Hadoop文档描述，Hadoop中可以使用Java类以及外部脚本两种方式来指定Host到Rack的映射关系。在这里我选择了使用Script的方式。<br>Hadoop对Script based的host到rack映射实现在org.apache.hadoop.net.ScriptBasedMapping类中。我们摘录了其中的一段代码：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> List&lt;String&gt; <span class="title">resolve</span><span class="params">(List&lt;String&gt; names)</span> </span>&#123;</span><br><span class="line">     List&lt;String&gt; m = <span class="keyword">new</span> ArrayList&lt;String&gt;(names.size());</span><br><span class="line"></span><br><span class="line">     <span class="keyword">if</span> (names.isEmpty()) &#123;</span><br><span class="line">       <span class="keyword">return</span> m;</span><br><span class="line">     &#125;</span><br><span class="line"></span><br><span class="line">     <span class="keyword">if</span> (scriptName == <span class="keyword">null</span>) &#123;</span><br><span class="line">       <span class="keyword">for</span> (String name : names) &#123;</span><br><span class="line">         m.add(NetworkTopology.DEFAULT_RACK);</span><br><span class="line">       &#125;</span><br><span class="line">       <span class="keyword">return</span> m;</span><br><span class="line">     &#125;</span><br><span class="line"></span><br><span class="line">     String output = runResolveCommand(names, scriptName);</span><br><span class="line">     <span class="keyword">if</span> (output != <span class="keyword">null</span>) &#123;</span><br><span class="line">       StringTokenizer allSwitchInfo = <span class="keyword">new</span> StringTokenizer(output);</span><br><span class="line">       <span class="keyword">while</span> (allSwitchInfo.hasMoreTokens()) &#123;</span><br><span class="line">         String switchInfo = allSwitchInfo.nextToken();</span><br><span class="line">         m.add(switchInfo);</span><br><span class="line">       &#125;</span><br></pre></td></tr></table></figure></p>
<p>从代码中我们可以看出，如果没有指定外部的映射脚本（net.topology.script.file.name）的话，Hadoop将所有的机器设置在DEFAULT_RACK（/default-rack）下；否则，则将以names作为输入获得映射脚本的输出。Hadoop在调用映射脚本时以IP作为输入，输出/rack$n。<br>在我的简单集群中，机器一个分成两个Rack。对于Rack的映射可以简单通过IP地址进行映射，从而得到所属的Rack id。我们将映射Shell脚本放置在Hadoop根目录中，在core-site.xml配置net.topology.script.file.name路径。配置更新到集群所有节点。如果在Shell脚本中加入打印信息，我们可以获得Hadoop集群执行过程中的一些调用信息。通过hadoop dfsadmin -report中报告节点信息上我们可以查看到Hadoop集群节点的Rack信息，同时在namenode的log中也可以看到节点的详细注册信息。</p>
<h3 id="ScriptBasedMapping调用">ScriptBasedMapping调用</h3><p>我们可以追究一下ScriptBasedMapping的调用关系。通过追踪Hadoop源码我们可以看到，在DataNodeManager的构造函数中有以下代码：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">this</span>.dnsToSwitchMapping = ReflectionUtils.newInstance(</span><br><span class="line">        conf.getClass(DFSConfigKeys.NET_TOPOLOGY_NODE_SWITCH_MAPPING_IMPL_KEY, </span><br><span class="line">            ScriptBasedMapping.class, DNSToSwitchMapping.class), conf);</span><br></pre></td></tr></table></figure></p>
<p>yarn的RackResolver中也有一段相同的代码。<br>而我们看conf.getClass的原型可以知道，这段代码首先获得net.topology.node.switch.mapping.impl对应的类，这个类必须实现 DNSToSwitchMapping接口，如果这个类没有配置，这使用默认类ScriptBasedMapping。下面是Hadoop源码中对getClass的描述：<br><figure class="highlight gherkin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">/<span class="keyword">*</span><span class="keyword">*</span> </span><br><span class="line">  <span class="keyword">*</span> Get the value of the <span class="variable">&lt;code&gt;</span>name<span class="variable">&lt;/code&gt;</span> property as a <span class="variable">&lt;code&gt;</span>Class<span class="variable">&lt;/code&gt;</span></span><br><span class="line">  <span class="keyword">*</span> implementing the interface specified by <span class="variable">&lt;code&gt;</span>xface<span class="variable">&lt;/code&gt;</span>.</span><br><span class="line">  <span class="keyword">*</span>   </span><br><span class="line">  <span class="keyword">*</span> If no such property is specified, then <span class="variable">&lt;code&gt;</span>defaultValue<span class="variable">&lt;/code&gt;</span> is </span><br><span class="line">  <span class="keyword">*</span> returned.</span><br><span class="line">  <span class="keyword">*</span> </span><br><span class="line">  <span class="keyword">*</span> An exception is thrown if the returned class does not implement the named</span><br><span class="line">  <span class="keyword">*</span> interface. </span><br><span class="line">  <span class="keyword">*</span> </span><br><span class="line">  <span class="keyword">*</span> <span class="comment">@param name the class name.</span></span><br><span class="line">  <span class="keyword">*</span> <span class="comment">@param defaultValue default value.</span></span><br><span class="line">  <span class="keyword">*</span> <span class="comment">@param xface the interface implemented by the named class.</span></span><br><span class="line">  <span class="keyword">*</span> <span class="comment">@return property value as a &lt;code&gt;Class&lt;/code&gt;, </span></span><br><span class="line">  <span class="keyword">*</span>         or <span class="variable">&lt;code&gt;</span>defaultValue<span class="variable">&lt;/code&gt;</span>.</span><br><span class="line">  <span class="keyword">*</span>/</span><br><span class="line"> public <span class="variable">&lt;U&gt;</span> Class<span class="variable">&lt;? extends U&gt;</span> getClass(String name, </span><br><span class="line">                                        Class<span class="variable">&lt;? extends U&gt;</span> defaultValue, </span><br><span class="line">                                        Class<span class="variable">&lt;U&gt;</span> xface) &#123;</span><br></pre></td></tr></table></figure></p>
<p>通过上面的代码分析我们可以得到以下两点：<br>1、Rackawareness在Hdfs以及Yarn中使用，用于数据及Container的分配指导；<br>2、Rackawareness首先判断java类实现是否存在，如果不存在再使用ScriptBasedMapping。</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


</div>




<div class="comments-count">
	
	  	<span></span>
		<a href="/2016/01/11/hadoop-rack/#disqus_thread" class="comments-count-link">Comments</a>
	
</div>

</footer>


    </article>






   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2015/12/09/flush-high-io/" title="flush线程为何一直在IO" itemprop="url">flush线程为何一直在IO</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Chongk-t" target="_blank" itemprop="author">Chongk-t</a>
		
  <p class="article-time">
    <time datetime="2015-12-09T01:46:33.375Z" itemprop="datePublished"> 发表于 2015-12-09</time>
    
  </p>
</header>
    <div class="article-content">
        
        <p>最近的实验中出现了iotop中观测到flush线程io百分比达到了99.99%。这个现象挺出乎意料的，因为在我的印象中flush进程是不应该有io操作的。所以我首先怀疑的是iotop中对io百分比的计算。</p>
<h3 id="iotop中对IO百分比的计算">iotop中对IO百分比的计算</h3><p>还是回到iotop的代码。在ui.py中，我们可以发现如下代码<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">delay2percent</span><span class="params">(delay)</span>:</span> <span class="comment"># delay in ns, duration in s</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">'%.2f %%'</span> % min(<span class="number">99.99</span>, delay / (duration * <span class="number">10000000.0</span>))</span><br></pre></td></tr></table></figure></p>
<p>可见进程的io百分比的计算来自于delay占统计时间（在iotop中为1s）的比值。而delay来自于进程TaskStats的<strong>blkio_delay_total</strong>，内核中具体的定义如下：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* Following four fields atomically updated using task-&gt;delays-&gt;lock */</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/* Delay waiting for synchronous block I/O to complete</span><br><span class="line"> * does not account for delays in I/O submission</span><br><span class="line"> */</span></span><br><span class="line">__u64	blkio_count;</span><br><span class="line">__u64	blkio_delay_total;</span><br></pre></td></tr></table></figure></p>
<p>内核注释写得很明确了，统计的是同步block I/O的等待时间，并不包括I/O提交延迟。<br>另一个问题是blkio_delay_total是什么时候被统计的？从内核代码中看，blkio_delay_total是由两个函数delayacct_blkio_start组合使用进行统计的。一个典型也是与本问题相关的使用是io_schedule。<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">void</span> __<span class="function">sched <span class="title">io_schedule</span><span class="params">(<span class="keyword">void</span>)</span></span><br><span class="line"></span>&#123;</span><br><span class="line">	<span class="keyword">struct</span> rq *rq = raw_rq();</span><br><span class="line"></span><br><span class="line">	delayacct_blkio_start();</span><br><span class="line">	atomic_inc(&amp;rq-&gt;nr_iowait);</span><br><span class="line">	current-&gt;in_iowait = <span class="number">1</span>;</span><br><span class="line">	schedule();</span><br><span class="line">	current-&gt;in_iowait = <span class="number">0</span>;</span><br><span class="line">	atomic_dec(&amp;rq-&gt;nr_iowait);</span><br><span class="line">	delayacct_blkio_end();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>从上面代码看，在线程io调度之前开始统计，在线程调度回来之后结束统计。因而io百分比表示的是因IO被调度出去的时间占墙钟时间的比例。<br>因而，flush线程这么大io百分比肯定是执行了io操作。</p>
<h3 id="flush线程的io操作">flush线程的io操作</h3><p>按照我的理解，flush线程的工作应该是将page cache中的dirty页传递到bio层，期间不会涉及到io操作。不过iotop的结果显然被狠狠地打脸了。跟踪一下代码看看。<br>flush线程在mm/Backing-dev.c文件中被创建：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kthread_run(bdi_start_fn, wb, <span class="string">"flush-%s"</span>,</span><br><span class="line">	dev_name(bdi-&gt;dev))</span><br></pre></td></tr></table></figure></p>
<p>线程函数穿越VFS接口最终到了ext4的<strong>ext4_da_writepages</strong>函数，这个函数负责最终的脏页write-back操作。整个代码过程看起来都很正常，期间还遇到了ext4的日志线程相关（jdb2)处理：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">handle = ext4_journal_start(inode, needed_blocks);</span><br><span class="line">......</span><br><span class="line">ext4_journal_stop(handle);</span><br><span class="line">......</span><br><span class="line">jbd2_journal_force_commit_nested(sbi-&gt;s_journal);</span><br></pre></td></tr></table></figure></p>
<p>这也很好理解，更新操作自然涉及到文件系统日志。然而，到以下几行代码时，我有点儿犯迷糊了<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (!mpd.io_done &amp;&amp; mpd.next_page != mpd.first_page) &#123;</span><br><span class="line">			<span class="keyword">if</span> (mpage_da_map_blocks(&amp;mpd) == <span class="number">0</span>)</span><br><span class="line">				mpage_da_submit_io(&amp;mpd);</span><br><span class="line">			mpd.io_done = <span class="number">1</span>;</span><br><span class="line">			ret = MPAGE_DA_EXTENT_TAIL;</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure></p>
<p>按常理而言，如果io_done未全部完成，继续提交就好了，这个map_blocks有些诡异。跟进去发现，这个mpage_da_map_blocks还涉及到了向磁盘申请Block相关的操作，预感这应该是问题所在了。</p>
<p>文件系统太复杂了，遇到了不太理解的问题，看看有没有哪位填友能帮我答疑解惑。万能的搜索引擎一搜，发现了<a href="http://m.blog.csdn.net/blog/kai_ding" target="_blank" rel="external">kai_ding</a>的文章<a href="http://m.blog.csdn.net/blog/kai_ding/9914629" target="_blank" rel="external">ext4的延迟分配</a>。好文共分享，我决定将<a href="https://chongk-t.github.io/2015/12/09/R-ext4/">这篇文章</a>转载到我的博客中。<br>从kai_ding的文章中可以看到，ext4提供延迟分配机制：页面在写回时再分配物理磁盘块与之对应。mpage_da_map_blocks()负责分配磁盘页并建立映射关系。<br>这也就解释了为什么flush线程会有这么大的io百分比。但是99.99%的io占比实在是太令人发指了，相当于flush没有时间干正事了。接下来是如何想办法如何解决它。</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


</div>




<div class="comments-count">
	
	  	<span></span>
		<a href="/2015/12/09/flush-high-io/#disqus_thread" class="comments-count-link">Comments</a>
	
</div>

</footer>


    </article>






   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2015/12/09/R-ext4/" title="转-ext4的延迟分配" itemprop="url">转-ext4的延迟分配</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Chongk-t" target="_blank" itemprop="author">Chongk-t</a>
		
  <p class="article-time">
    <time datetime="2015-12-08T16:29:23.130Z" itemprop="datePublished"> 发表于 2015-12-09</time>
    
  </p>
</header>
    <div class="article-content">
        
        <p><strong>本文转自<a href="http://m.blog.csdn.net/blog/kai_ding/9914629" target="_blank" rel="external">kai_ding博客</a>，好文跟大家分享</strong><br>Ext4文件系统在应用程序调用write的时候并不为缓存页面分配对应的物理磁盘块，当文件的缓存页面真正要被刷新至磁盘中时，ext4会为所有未分配物理磁盘块的页面缓存分配尽量连续的磁盘块。<br>Linux文件系统Vfs层总是将应用程序的写入请求分割成页面（默认大小4KB）为单位，对于每个页面，VFS会检查其是否已经为其创建了buffer_head结构，如果没有创建，则为其创建buffer_head，否则检查每个buffer_head的状态，如该buffer_head是否已经与物理磁盘块建立映射等，这些功能是由write_begin()函数实现的，该函数是由VFS提供的一个接口，具体文件系统负责实现该接口，如ext3文件系统的ext3_write_begin()。而ext4如果采用了delay allocation特性的话，其实现的函数为ext4_da_write_begin()。<br>ext4_da_write_begin()会检查页面所有的buffer_head的状态，如buffer_head是否已经建立映射等，对于没有建立映射的buffer_head，需要将其与物理磁盘块建立映射关系，调用的函数是ext4_da_get_block_prep()，该函数又调用了ext4_map_blocks()来建立逻辑块和物理磁盘块的映射关系，如果启用extent特性的话，那么该函数又调用了ext4_ext_map_blocks(handle, inode, map, 0)来建立这种映射关系，之所以列举该函数的参数是要特别注意其最后一个参数0，这是一个标志位，调用者ext4_map_blocks()将该标志位设置为0，告诉被调用者，如果没有建立映射关系，那么此刻无需真正地分配物理磁盘块。这在ext4_ext_map_blocks函数中可以看到会有对该标志位的判断。就不再详细列举代码了。因为在ext4_map_blocks()中并没有建立映射关系，因此其向ext4_da_get_block_prep()返回0，表示没有映射，在ext4_da_get_block_prep()函数中判断如果返回值为0，那么为当前block设置标志位BH_New，BH_Mapped,BH_Delay（表示该块在写入的时候再进行延迟分配）。<br><img src="http://ww2.sinaimg.cn/mw690/79382a93jw1eyspjo01kkj20e50833zf.jpg" alt="1"><br><img src="http://ww4.sinaimg.cn/mw690/79382a93jw1eyspjo5xoej20gj09m419.jpg" alt="2"></p>
<p>以上我们确认了在ext4中延迟分配的前半部分，即应用程序将数据写入文件时只是简单地将数据以页面为单位写入页面缓存中，而并不真正地为其分配物理磁盘块。接下来我们要弄明白的是，ext4何时会为缓存中未分配物理磁盘块的缓存分配磁盘空间。</p>
<p>当刷新线程开始将脏的缓存页面写回至物理磁盘时，根据我们之前的描述，回写线程会以文件为单位进行回写，即对脏inode链表上的所有脏inode依次回写。对于每个脏inode（也即每个脏的文件），回写线程会将inode上的所有脏页面进行回写，这时候就需要判断每个脏页面的状态了。</p>
<p>回写线程中实现的时候将一个文件的脏页面分多次进行回写，每个回写一部分脏页面。关于回写机制可参考Linux的“脏页面回写机制”。回写脏页面最终调用到函数writepages，与writebegin一样，它也是VFS提供的一个虚拟接口，由具体文件系统负责相应的实现。对于采用延迟分配的ext4文件系统来说，该函数的具体实现是ext4_da_writepages()。该函数中实现的时候有三个要点：</p>
<p> 要将逻辑上连续的脏且尚未建立磁盘块映射到物理页面形成一个extent，以便可采用ext4的mblock分配策略提升文件连续性，这也是我们后面要介绍的内容；<br>对1中连续页面形成的extent，为其进行磁盘块分配，分配采用了ext4的mblock allocation策略。<br>提交2中的extent至bio层完成脏页面的写入，此时已经为尚未映射的缓存页面分配了物理磁盘块。</p>
<p><img src="http://ww2.sinaimg.cn/mw690/79382a93jw1eyspjnqx19j20f10a2wgw.jpg" alt="3"></p>
<p>上图描述了延迟分配的核心思想：等到刷新脏缓存页面时再建立脏页面与物理磁盘块之间的联系，而且，分配之前将逻辑上连续的文件块映射至物理上连续的磁盘块。在ext4_da_writepages()函数中调用了三个非常重要的函数来完成上述功能：write_cache_pages_da()负责将逻辑上连续的文件块合并成一个extent；mpage_da_map_blocks()负责为合并后的extent建立映射关系；mpage_da_submit_io()负责提交上面映射的extent。</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


</div>




<div class="comments-count">
	
	  	<span></span>
		<a href="/2015/12/09/R-ext4/#disqus_thread" class="comments-count-link">Comments</a>
	
</div>

</footer>


    </article>






   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2015/12/07/HiBench-SSH-Banner-Issue/" title="HiBench的一个Bug-SSH Banner惹的祸" itemprop="url">HiBench的一个Bug-SSH Banner惹的祸</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Chongk-t" target="_blank" itemprop="author">Chongk-t</a>
		
  <p class="article-time">
    <time datetime="2015-12-07T15:14:14.350Z" itemprop="datePublished"> 发表于 2015-12-07</time>
    
  </p>
</header>
    <div class="article-content">
        
        <p>今天将HiBench移到了Arm64平台，想看看Arm平台Hadoop的表现。毕竟是Java+Python平台，整个移植过程非常顺利。点杆执行，然后喝咖啡去了。回来一看，report下的monitor.log及monitor.html都没有生成。大呼又踩到坑了。</p>
<p>好吧，习惯了修修补补，让我们看看又有哪些问题。<br>HiBench的监控脚本最终会走到<strong>monitor.py</strong>, __main__函数走下发现输出被丢了，难怪被坑得无影无踪。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">os.close(<span class="number">0</span>)</span><br><span class="line">os.close(<span class="number">1</span>)</span><br><span class="line">os.close(<span class="number">2</span>)</span><br></pre></td></tr></table></figure></p>
<p>把这几行注释掉，Bug现出了原形：Int类型转换Exception，“Enjoy~ 无法转换成Int”。<br>忽然想起公司同事有用SSH Banner做标记的情形，跟“在此撒泡尿，这段时间这个服务器归我”差不多。这个倒霉的服务器就被标上了<br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Enjoy~</span><br></pre></td></tr></table></figure></p>
<p>仔细看了一眼发现原来HiBench使用SSH登录的时间戳作为记录时间，默认SSH登录时返回的就是登录时间，没想到一个Banner被我给撞上了。<br>好吧，向HiBench git上提交一个<a href="https://github.com/intel-hadoop/HiBench/issues/161" target="_blank" rel="external">issue</a>，patch就让他们自己打吧，我太懒了。</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


</div>




<div class="comments-count">
	
	  	<span></span>
		<a href="/2015/12/07/HiBench-SSH-Banner-Issue/#disqus_thread" class="comments-count-link">Comments</a>
	
</div>

</footer>


    </article>






   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2015/12/06/NewIoTop/" title="如何让iotop显示read/write系统调用次数及系统调用请求数据大小" itemprop="url">如何让iotop显示read/write系统调用次数及系统调用请求数据大小</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Chongk-t" target="_blank" itemprop="author">Chongk-t</a>
		
  <p class="article-time">
    <time datetime="2015-12-06T15:49:11.234Z" itemprop="datePublished"> 发表于 2015-12-06</time>
    
  </p>
</header>
    <div class="article-content">
        
        <pre><code>最近在忙着优化Hadoop集群。遇到的问题是Disk利用率一直没有达到物理带宽，其他资源也没有出现达到瓶颈的迹象。这让我颇为不爽，决定一探究竟。
首先使用的工具是iotop。熟悉iotop的同学都知道，iotop执行时在终端顶端出现<span class="keyword">Total</span>/Actual DISK <span class="keyword">READ</span>/WRITE四个值。<span class="keyword">Total</span>与Actual的区别也让我费了一段时间，我的理解是：<span class="keyword">Total</span>值是bio层从<span class="keyword">file</span> cache到ioschedule传递的数据量；Actual是ioschedule到disk的之间的数据量。
在跟另外一个运行良好的Hadoop集群对比之后我发现这个问题集群的Actual Disk数据有所差距。于是我决定对Syscall层、<span class="keyword">file</span> cache层的数据通量做一个全面的分析。这就要求对iotop的源码做一些小的修改。
</code></pre><h2 id="iotop的工作原理">iotop的工作原理</h2><pre><code>分析iotop的源码过程让我深刻了解了TaskStats机制。内核Document对TaskStats的描述是：
</code></pre><p><img src="http://ww2.sinaimg.cn/mw690/79382a93jw1eyqdbunlmij20bu031jrk.jpg" alt="TaskStats"><br>从上面的描述来看，TaskStats是一个用于获得每个进程执行数据的Netlink接口。iotop的源码中也是通过Netlink向TaskStats请求每个进程read_bytes、write_bytes等获得进程的I/O数据从而累加起来得到Total Disk相关数据的（Actual Disk数据则是从/proc/vmstat中的pgpgin及pgpgout获得）。<br>    于是我分析了内核对于TaskStats的定义，看看是否有对I/O系统调用次数及系统调用数据量累积相关统计。运气还不错，内核对TaskStats的定义如下：<br><img src="http://ww4.sinaimg.cn/mw690/79382a93jw1eyqdbufrxhj20e3051aaq.jpg" alt="TaskStats-Define"><br>从上面定义我们看到了read/write_char及read/write_syscalls几个统计变量，从内核的描述可以看出这就是对系统调用请求数据量以及系统调用次数的统计。这让我们想让iotop输出这两个信息的希望成为了可能。</p>
<h2 id="对iotop稍作修改">对iotop稍作修改</h2><pre><code>接下来我们看看iotop对于从TaskStats请求返回的数据的处理方式。在代码中我看到了一个数据结构来记录返回数据偏移对应的内容相得情况。这就非常明了了，iotop请求返回的就是TaskStats的结构。于是我们照葫芦画瓢，在结构中添加了几项，获取想要的<span class="built_in">i</span>/o信息。修改后结构如下：
</code></pre><p><img src="http://ww2.sinaimg.cn/mw690/79382a93jw1eyqdbttfw3j20ag05w0t5.jpg" alt="code-add"><br>剩下的修改就是修改一些累计方式以及显示方式了，这就没有必要详述了。</p>
<h2 id="最终效果">最终效果</h2><pre><code>修改之后的最终效果当然就是newiotop能够显示<span class="keyword">read</span>/<span class="keyword">write</span> <span class="keyword">syscall</span>的数目及<span class="keyword">syscall</span>请求的数据量了。如下图所示：
</code></pre><p><img src="http://ww4.sinaimg.cn/mw690/79382a93jw1eyqdcqcsenj212404ejsq.jpg" alt="ui"></p>
<p><strong>如果有同学需要使用这些代码我很乐意分享给大家，请不要犹豫邮件、微博等跟我联系</strong></p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


</div>




<div class="comments-count">
	
	  	<span></span>
		<a href="/2015/12/06/NewIoTop/#disqus_thread" class="comments-count-link">Comments</a>
	
</div>

</footer>


    </article>






   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2015/12/06/我对技术博客的理解/" title="我对技术博客的理解" itemprop="url">我对技术博客的理解</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Chongk-t" target="_blank" itemprop="author">Chongk-t</a>
		
  <p class="article-time">
    <time datetime="2015-12-06T14:11:14.438Z" itemprop="datePublished"> 发表于 2015-12-06</time>
    
  </p>
</header>
    <div class="article-content">
        
        <p>互联网公司的工作是技术驱动的。互联网公司的高速运转给我们提供了很多深入的机会，每天的工作都能接触到错综复杂的技术，当你越是深入、越是踏实时，你接触的技术就越是细、越是复杂。<br>一直就打算写博客。以前没毕业时也写过一些，终究没有坚持下来。一个重要的原因当时接触的东西比较简单，不够深入就不好意思分享。想法虽然简单，却也情有可原。<br>博客，是跟自己在说话。无须矫情，也无法虚假。<br>希望我的思考能够帮助其他人。</p>
<h2 id="博客文章的三个功能">博客文章的三个功能</h2><h3 id="审视技术的扎实程度">审视技术的扎实程度</h3><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">写作促进思考。通过文字的表达带动自己对技术的审视-故事是否完整、脉络是否清晰等。</span><br><span class="line">一个完整的技术故事，对于技术的提升大有裨益。</span><br></pre></td></tr></table></figure>
<h3 id="希望能够帮助他人">希望能够帮助他人</h3><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">技术是开放的。我自己深受其害的坑不希望其他人再踩一次。我也非常感激之前让我跳过很多坑的博主们。</span><br></pre></td></tr></table></figure>
<h3 id="备忘">备忘</h3><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">除非填坑过程坎坷，很多技术细节很容易忘记。博客就像一条走过的路，偶尔回首总能温故知新。</span><br></pre></td></tr></table></figure>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


</div>




<div class="comments-count">
	
	  	<span></span>
		<a href="/2015/12/06/我对技术博客的理解/#disqus_thread" class="comments-count-link">Comments</a>
	
</div>

</footer>


    </article>







</div>
      <div class="openaside"><a class="navbutton" href="#" title="显示侧边栏"></a></div>

<div id="asidepart">
<div class="closeaside"><a class="closebutton" href="#" title="隐藏侧边栏"></a></div>
<aside class="clearfix">

  
  <div class="archiveslist">
    <p class="asidetitle"><a href="/archives">归档</a></p>
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/01/">一月 2016</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/12/">十二月 2015</a><span class="archive-list-count">5</span></li></ul>
  </div>


  
<div class="github-card">
<p class="asidetitle">Github 名片</p>
<div class="github-card" data-github="chongk-t" data-width="220" data-height="119" data-theme="medium">
<script type="text/javascript" src="//cdn.jsdelivr.net/github-cards/latest/widget.js" ></script>
</div>
  </div>



  

  

  <div class="linkslist">
  <p class="asidetitle">友情链接</p>
    <ul>
        
    </ul>
</div>

  


  <div class="rsspart">
	<a href="/atom.xml" target="_blank" title="rss">RSS 订阅</a>
</div>

  <div class="weiboshow">
  <p class="asidetitle">新浪微博</p>
    <iframe width="100%" height="119" class="share_self"  frameborder="0" scrolling="no" src="http://widget.weibo.com/weiboshow/index.php?language=&width=0&height=119&fansRow=2&ptype=1&speed=0&skin=9&isTitle=1&noborder=1&isWeibo=0&isFans=0&uid=null&verifier=&dpc=1"></iframe>
</div>


</aside>
</div>
    </div>
    <footer><div id="footer" >
	
	<div class="line">
		<span></span>
		<div class="author"></div>
	</div>
	
	
	<section class="info">
		<p> Coding Thoughts. <br/>
			Thinking and coding down.</p>
	</section>
	 
	<div class="social-font" class="clearfix">
		
		<a href="http://weibo.com/2033724051" target="_blank" class="icon-weibo" title="微博"></a>
		
		
		<a href="https://github.com/chongk-t" target="_blank" class="icon-github" title="github"></a>
		
		
		
		
		
		
		
		
		
		<a href="mailto:chongk-t@hotmail.com" target="_blank" class="icon-email" title="Email Me"></a>
		
	</div>
			
		

		<p class="copyright">
		Powered by <a href="http://hexo.io" target="_blank" title="hexo">hexo</a> and Theme by <a href="https://github.com/wuchong/jacman" target="_blank" title="Jacman">Jacman</a> © 2016 
		
		<a href="/about" target="_blank" title="Chongk-t">Chongk-t</a>
		
		
		</p>
</div>
</footer>
    <script src="/js/jquery-2.0.3.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>
<script src="/js/jquery.qrcode-0.12.0.min.js"></script>

<script type="text/javascript">
$(document).ready(function(){ 
  $('.navbar').click(function(){
    $('header nav').toggleClass('shownav');
  });
  var myWidth = 0;
  function getSize(){
    if( typeof( window.innerWidth ) == 'number' ) {
      myWidth = window.innerWidth;
    } else if( document.documentElement && document.documentElement.clientWidth) {
      myWidth = document.documentElement.clientWidth;
    };
  };
  var m = $('#main'),
      a = $('#asidepart'),
      c = $('.closeaside'),
      o = $('.openaside');
  c.click(function(){
    a.addClass('fadeOut').css('display', 'none');
    o.css('display', 'block').addClass('fadeIn');
    m.addClass('moveMain');
  });
  o.click(function(){
    o.css('display', 'none').removeClass('beforeFadeIn');
    a.css('display', 'block').removeClass('fadeOut').addClass('fadeIn');      
    m.removeClass('moveMain');
  });
  $(window).scroll(function(){
    o.css("top",Math.max(80,260-$(this).scrollTop()));
  });
  
  $(window).resize(function(){
    getSize(); 
    if (myWidth >= 1024) {
      $('header nav').removeClass('shownav');
    }else{
      m.removeClass('moveMain');
      a.css('display', 'block').removeClass('fadeOut');
      o.css('display', 'none');
        
    }
  });
});
</script>





<script type="text/javascript">

var disqus_shortname = 'chongkt';

(function(){
  var dsq = document.createElement('script');
  dsq.type = 'text/javascript';
  dsq.async = true;
  dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
  (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
}());
(function(){
  var dsq = document.createElement('script');
  dsq.type = 'text/javascript';
  dsq.async = true;
  dsq.src = '//' + disqus_shortname + '.disqus.com/count.js';
  (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
}());
</script>






<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
$(document).ready(function(){ 
  $('.article-content').each(function(i){
    $(this).find('img').each(function(){
      if ($(this).parent().hasClass('fancybox')) return;
      var alt = this.alt;
      if (alt) $(this).after('<span class="caption">' + alt + '</span>');
      $(this).wrap('<a href="' + this.src + '" title="' + alt + '" class="fancybox"></a>');
    });
    $(this).find('.fancybox').each(function(){
      $(this).attr('rel', 'article' + i);
    });
  });
  if($.fancybox){
    $('.fancybox').fancybox();
  }
}); 
</script>



<!-- Analytics Begin -->



<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?e6d1f421bbc9962127a50488f9ed37d1";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>



<!-- Analytics End -->

<!-- Totop Begin -->

	<div id="totop">
	<a title="返回顶部"><img src="/img/scrollup.png"/></a>
	</div>
	<script src="/js/totop.js"></script>

<!-- Totop End -->

<!-- MathJax Begin -->
<!-- mathjax config similar to math.stackexchange -->


<!-- MathJax End -->

<!-- Tiny_search Begin -->

<!-- Tiny_search End -->

  </body>
 </html>
